# RainbowBrowserAI Environment Configuration
# Copy this file to .env and fill in your configuration values

# ========== Browser Configuration ==========
RAINBOW_MOCK_MODE=false                # Enable/disable mock mode for testing
BROWSER_HEADLESS=true                  # Run browser in headless mode
BROWSER_TIMEOUT_MS=30000               # Browser operation timeout in milliseconds
BROWSER_WINDOW_WIDTH=1920              # Browser window width
BROWSER_WINDOW_HEIGHT=1080             # Browser window height

# ChromeDriver Configuration
CHROMEDRIVER_PORT=9515                 # ChromeDriver service port
CHROMEDRIVER_PATH=                     # Custom ChromeDriver path (optional)
CHROME_BINARY_PATH=                    # Custom Chrome binary path (optional)

# ========== Server Configuration ==========
SERVER_HOST=0.0.0.0                    # Server bind address
SERVER_PORT=3001                       # API server port
CORS_ORIGIN=*                          # CORS allowed origins

# ========== Session Management ==========
SESSION_TIMEOUT_SECONDS=1800           # Session timeout (30 minutes)
MAX_CONCURRENT_SESSIONS=10             # Maximum concurrent browser sessions
BROWSER_POOL_SIZE=5                    # Browser pool size
SESSION_CLEANUP_INTERVAL=300           # Session cleanup interval (5 minutes)

# ========== Perception System ==========
PERCEPTION_CACHE_SIZE=1000             # Perception cache size
PERCEPTION_TIMEOUT_MS=5000             # Maximum perception timeout
LIGHTNING_MODE_TIMEOUT_MS=50           # Lightning mode timeout
QUICK_MODE_TIMEOUT_MS=200              # Quick mode timeout
STANDARD_MODE_TIMEOUT_MS=1000          # Standard mode timeout
DEEP_MODE_TIMEOUT_MS=5000              # Deep mode timeout

# ========== AI Integration (Optional) ==========
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com

# Claude Configuration
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# CLAUDE_MODEL=claude-3-sonnet-20240229

# Ollama Local Model Configuration
# OLLAMA_ENDPOINT=http://localhost:11434
# OLLAMA_MODEL=llama2

AI_TIMEOUT_SECONDS=30                  # AI request timeout

# ========== Logging Configuration ==========
RUST_LOG=info                          # Log level (trace, debug, info, warn, error)
LOG_FORMAT=json                        # Log format (json, pretty)
LOG_FILE_PATH=                         # Log file path (optional)

# ========== Performance Settings ==========
ENABLE_PERFORMANCE_MONITORING=true     # Enable performance monitoring
METRICS_COLLECTION_INTERVAL=60         # Metrics collection interval (seconds)

# ========== Security Settings ==========
ENABLE_CORS=true                       # Enable CORS
REQUIRE_API_KEY=false                  # Require API key for requests
API_KEY=                               # API key if required

# ========== Development Settings ==========
ENABLE_DEBUG_ENDPOINTS=false           # Enable debug API endpoints
ENABLE_SWAGGER_UI=true                 # Enable Swagger UI documentation
RELOAD_ON_CHANGE=false                 # Enable hot reload during development